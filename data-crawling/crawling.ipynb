{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pymysql\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pymysql.connect(host='localhost', user='ssafy', password='ssafy', \n",
    "                      db='access_db', charset='utf8mb4', autocommit=True)\n",
    "cur = con.cursor()\n",
    "\n",
    "sql = \"INSERT INTO table_name (value1, value2) VALUES (123, '이름');\"\n",
    "cur.execute(sql)\n",
    "\n",
    "con.commit()\n",
    "con.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환율"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### api 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchange_rate_api(date):\n",
    "  API_HOST = \"https://www.koreaexim.go.kr/site/program/financial/exchangeJSON\"\n",
    "  key = \"?authkey=b60MyMtLUDVQyyiDjZRdFGbKxoJBypkl\"\n",
    "  search = \"&searchdate=\"+date\n",
    "  data = \"&data=AP01\"\n",
    "  \n",
    "  url = API_HOST+key+search+data\n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\"}\n",
    "\n",
    "  try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response\n",
    "  except Exception as ex:\n",
    "    print(ex)\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [00:30<00:00, 14.24it/s]\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start='10/29/2021', end='12/31/2022')\n",
    "\n",
    "result_list = []\n",
    "for date in tqdm(date_range):\n",
    "  if dt.date.weekday(date) in (5, 6) :\n",
    "    continue\n",
    "  str_date = str(date).split(\" \")[0]\n",
    "  \n",
    "  r = json.loads(exchange_rate_api(str_date).text)\n",
    "  \n",
    "  flag = True\n",
    "  for data in r:\n",
    "    if data[\"result\"] == 4:\n",
    "      flag = False\n",
    "      break\n",
    "    if data[\"cur_nm\"] in ('미국 달러', '일본 옌', '유로') :\n",
    "      if(data[\"cur_nm\"] == '일본 옌'):\n",
    "        result_list.append(\"('{}', '{}', {})\".format(str_date, '일본 100엔', data[\"deal_bas_r\"].replace(\",\", \"\")))\n",
    "      else:\n",
    "        result_list.append(\"('{}', '{}', {})\".format(str_date, data['cur_nm'], data[\"deal_bas_r\"].replace(\",\", \"\")))\n",
    "  if flag == False:\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(cur_20221231).p\", \"wb\") as f:\n",
    "  pickle.dump(result_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.p\", \"rb\") as f:\n",
    "  result_list = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pymysql.connect(host='localhost', user='ssafy', password='ssafy', \n",
    "                      db='access_db', charset='utf8mb4', autocommit=True)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO currency(cur_date, cur_name, cur_rate) VALUES \" + \",\".join(result_list)\n",
    "cur.execute(sql)\n",
    "con.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원자재(석유, 금)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- API가 2020년부터 데이터가 있어서 사용이 불가능.. 하하\n",
    "- Naver를 통해 크롤링해야할 듯.\n",
    "  - 주식, 코스닥 코스피도 동일\n",
    "- 석유 : 경유, 휘발유, 등유 3가지 평균값 활용\n",
    "  - 네이버 증권에는 등유가 없어서 경유, 휘발유만 사용?\n",
    "- 금 : 국내금, 국제금 2가지 각각 활용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### api 함수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 오일\n",
    "- 휘발유 : OIL_GSL\n",
    "- 경유 : OIL_LO\n",
    "- 예시 : https://finance.naver.com/marketindex/oilDailyQuote.naver?marketindexCd=OIL_GSL&page=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oil_api(oil_type):\n",
    "  page = 641\n",
    "  end = 15\n",
    "  oil = \"휘발유\" if oil_type == \"OIL_GSL\" else \"경유\"\n",
    "  HOST = \"https://finance.naver.com/marketindex/oilDailyQuote.naver?marketindexCd={}&page=\".format(oil_type)\n",
    "  \n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\"}\n",
    "\n",
    "  try:\n",
    "    result_list = []\n",
    "    for p in tqdm(range(page, end-1, -1), \n",
    "              total = page-end+1, ## 전체 진행수\n",
    "              desc = 'Desc', ## 진행률 앞쪽 출력 문장\n",
    "              ncols = 80, ## 진행률 출력 폭 조절\n",
    "              leave = True, ## True 반복문 완료시 진행률 출력 남김. False 남기지 않음.\n",
    "            ):\n",
    "      url = HOST+str(p)\n",
    "      response = requests.get(url, headers=headers)\n",
    "      result_list.extend(oil_bs(response, oil))\n",
    "      \n",
    "      time.sleep(0.5)\n",
    "      \n",
    "    return result_list\n",
    "  except Exception as ex:\n",
    "    print(\"oil_api 오류 발생\")\n",
    "    print(ex)\n",
    "\n",
    "def oil_bs(response, oil_type):\n",
    "  start = dt.datetime.strptime(\"2011-01-01\", \"%Y-%m-%d\")\n",
    "  end = dt.datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "  \n",
    "  soup = bs(response.text, \"html.parser\")\n",
    "  result = soup.select(\"tbody > tr\")\n",
    "  \n",
    "  result_list = []  \n",
    "  try:\n",
    "    for p in result[::-1]:\n",
    "      state = p.get(\"class\")[0]\n",
    "      td_list = p.select(\"td\")\n",
    "      td = [td_list[0].getText().strip().replace(\".\", \"-\"), oil_type, state, td_list[1].getText().strip(), td_list[2].getText().strip(), td_list[3].getText().strip()[1:-1].strip()]\n",
    "      \n",
    "      cur_date = dt.datetime.strptime(td[0], \"%Y-%m-%d\")\n",
    "      start_diff = (cur_date - start).total_seconds()\n",
    "      end_diff= (end - cur_date).total_seconds()\n",
    "      if start_diff < 0 or end_diff <= 0:\n",
    "        continue\n",
    "      \n",
    "      result_list.append(\"('{}', '{}', '{}', {}, {}, {})\".format(td[0], td[1], td[2], td[3].replace(\",\", \"\"), td[4], td[5]))\n",
    "  except Exception as ex:\n",
    "    print(\"oil_bs 오류 발생\")\n",
    "    print(ex)\n",
    "  \n",
    "  return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 금\n",
    "- 국제금\n",
    "  - 예시 : https://finance.naver.com/marketindex/worldDailyQuote.naver?marketindexCd=CMDT_GC&fdtc=2&page=446\n",
    "- 국내금\n",
    "  - 예시 : https://finance.naver.com/marketindex/goldDailyQuote.naver?&page=305\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_api(gold_type):\n",
    "  if gold_type == \"national\":\n",
    "    HOST = \"https://finance.naver.com/marketindex/worldDailyQuote.naver?marketindexCd=CMDT_GC&fdtc=2&page=\"\n",
    "    page = 446\n",
    "    end = 10\n",
    "    gold = \"국제금(달러/트로이온스)\"\n",
    "  else :\n",
    "    HOST = \"https://finance.naver.com/marketindex/goldDailyQuote.naver?&page=\"\n",
    "    page = 305\n",
    "    end = 8\n",
    "    gold = \"국내금(원/g)\"\n",
    "  \n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\"}\n",
    "\n",
    "  try:\n",
    "    result_list = []\n",
    "    for p in tqdm(range(page, end-1, -1), \n",
    "              total = page-end+1, ## 전체 진행수\n",
    "              desc = 'Desc', ## 진행률 앞쪽 출력 문장\n",
    "              ncols = 80, ## 진행률 출력 폭 조절\n",
    "              leave = True, ## True 반복문 완료시 진행률 출력 남김. False 남기지 않음.\n",
    "            ):\n",
    "      url = HOST+str(p)\n",
    "      response = requests.get(url, headers=headers)\n",
    "      result_list.extend(gold_bs(response, gold))\n",
    "      \n",
    "      time.sleep(0.5)\n",
    "      \n",
    "    return result_list\n",
    "  except Exception as ex:\n",
    "    print(\"gold_api 오류 발생\")\n",
    "    print(ex)\n",
    "\n",
    "def gold_bs(response, gold_type):\n",
    "  start = dt.datetime.strptime(\"2011-01-01\", \"%Y-%m-%d\")\n",
    "  end = dt.datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "  \n",
    "  soup = bs(response.text, \"html.parser\")\n",
    "  result = soup.select(\"tbody > tr\")\n",
    "  \n",
    "  result_list = []  \n",
    "  try:\n",
    "    for p in result[::-1]:\n",
    "      state = p.get(\"class\")[0]\n",
    "      td_list = p.select(\"td\")\n",
    "      \n",
    "      td = [td_list[0].getText().strip().replace(\".\", \"-\"), gold_type, state, td_list[1].getText().strip(), td_list[2].getText().strip()]\n",
    "      if gold_type == \"국제금(달러/트로이온스)\" :\n",
    "        td.append(td_list[3].getText().strip()[1:-1].strip())\n",
    "      else :\n",
    "        temp_value = float(td[-2].replace(\",\", \"\")) + (float(td[-1].replace(\",\", \"\")) if td[2] == 'down' else (-float(td[-1].replace(\",\", \"\"))))\n",
    "        td.append(str(round(float(td[-1].replace(\",\", \"\")) / temp_value * 100, 2)))\n",
    "      \n",
    "      cur_date = dt.datetime.strptime(td[0], \"%Y-%m-%d\")\n",
    "      start_diff = (cur_date - start).total_seconds()\n",
    "      end_diff= (end - cur_date).total_seconds()\n",
    "      if start_diff < 0 or end_diff <= 0:\n",
    "        continue\n",
    "      \n",
    "      result_list.append(\"('{}', '{}', '{}', {}, {}, {})\".format(td[0], td[1], td[2], td[3].replace(\",\", \"\"), td[4].replace(\",\", \"\"), td[5]))\n",
    "  except Exception as ex:\n",
    "    print(\"gold_bs 오류 발생\")\n",
    "    print(ex)\n",
    "  \n",
    "  return result_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 수집"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 금"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Desc: 100%|███████████████████████████████████| 437/437 [04:29<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = gold_api(\"national\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Desc: 100%|███████████████████████████████████| 298/298 [03:10<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = gold_api(\"daily\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(domestic_gold_230414).p\", \"wb\") as f:\n",
    "  pickle.dump(result_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(domestic_gold_230414).p\", \"rb\") as f:\n",
    "  result_list = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pymysql.connect(host='localhost', user='ssafy', password='ssafy', \n",
    "                      db='access_db', charset='utf8mb4', autocommit=True)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO material(material_date, material_name, material_state, material_rate, material_change, material_change_rate) VALUES \" + \",\".join(result_list)\n",
    "cur.execute(sql)\n",
    "con.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주식 시세!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용 주식 머시깽이들\n",
    "  - 전기 : 삼성전자(005930), LG전자(066570)\n",
    "  - 화학 : LG화학(051910), 롯데케미칼(011170)\n",
    "  - 생명 : 셀트리온(068270), 녹십자(006280)\n",
    "  - IT : Naver(035420), SK텔레콤(017670)\n",
    "  - 엔터 : SM엔터테이먼트(041510), JYP엔터테이먼트(035900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### api 함수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주식 머시깽이들\n",
    "- 예시 : https://finance.naver.com/item/sise_day.naver?code={}&page="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_api(stock_type):\n",
    "  page = 304  # 시작 페이지\n",
    "  end = 8     # 끝 페이지\n",
    "  \n",
    "  if stock_type == \"035420\":\n",
    "    stock_origin = \"네이버\"\n",
    "    stock = \"G IT\"\n",
    "  elif stock_type ==\"005930\":\n",
    "    stock_origin = \"삼성전자\"\n",
    "    stock = \"A 전자\"\n",
    "  elif stock_type ==\"051910\":\n",
    "    stock_origin = \"LG화학\"\n",
    "    stock = \"B 화학\"\n",
    "  elif stock_type ==\"068270\":\n",
    "    stock_origin = \"셀트리온\"\n",
    "    stock = \"C 생명\"\n",
    "  elif stock_type ==\"041510\":\n",
    "    stock_origin = \"SM엔터\"\n",
    "    stock = \"E 엔터테이먼트\"\n",
    "  elif stock_type ==\"066570\":\n",
    "    stock_origin = \"LG전자\"\n",
    "    stock = \"F 전자\"\n",
    "  elif stock_type ==\"011170\":\n",
    "    stock_origin = \"롯데케미칼\"\n",
    "    stock = \"G 화학\"\n",
    "  elif stock_type ==\"006280\":\n",
    "    stock_origin = \"녹십자\"\n",
    "    stock = \"H 생명\"\n",
    "  elif stock_type ==\"017670\":\n",
    "    stock_origin = \"SK텔레콤\"\n",
    "    stock = \"I IT\"\n",
    "  elif stock_type ==\"035900\":\n",
    "    stock_origin = \"JYP엔터\"\n",
    "    stock = \"J 엔터테이먼트\"\n",
    "  \n",
    "  HOST = \"https://finance.naver.com/item/sise_day.naver?code={}&page=\".format(stock_type)\n",
    "  \n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\", 'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "  try:\n",
    "    result_list = []\n",
    "    for p in tqdm(range(page, end-1, -1), \n",
    "              total = page-end+1, ## 전체 진행수\n",
    "              desc = 'Desc', ## 진행률 앞쪽 출력 문장\n",
    "              ncols = 80, ## 진행률 출력 폭 조절\n",
    "              leave = True, ## True 반복문 완료시 진행률 출력 남김. False 남기지 않음.\n",
    "            ):\n",
    "      url = HOST+str(p)\n",
    "      req = Request(url, headers=headers)\n",
    "      with urlopen(req) as response:\n",
    "        if not response is None:\n",
    "          result_list.extend(stock_bs(response, stock_origin, stock))\n",
    "      \n",
    "      time.sleep(0.5)\n",
    "      \n",
    "    return result_list\n",
    "  except Exception as ex:\n",
    "    print(\"stock_api 오류 발생\")\n",
    "    print(ex)\n",
    "\n",
    "def stock_bs(response, origin, after):\n",
    "  start = dt.datetime.strptime(\"2011-01-01\", \"%Y-%m-%d\")\n",
    "  end = dt.datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "  \n",
    "  soup = bs(response, \"html.parser\")\n",
    "  result = soup.select('table > tr[onmouseover=\"mouseOver(this)\"]')\n",
    "  \n",
    "  result_list = []  \n",
    "  try:\n",
    "    for p in result[::-1]:\n",
    "      td_list = p.select(\"td\")\n",
    "      \n",
    "      if td_list[2].select_one(\"img\") is None:\n",
    "        state = \"same\"\n",
    "      # elif td_list[2].select_one(\"img\")[\"alt\"].strip() == \"상승\" :\n",
    "      #   state = \"up\" \n",
    "      # elif td_list[2].select_one(\"img\")[\"alt\"].strip() == \"하락\" :\n",
    "      #   state = \"down\"\n",
    "      else :\n",
    "        state = \"up\" if \"up\" in td_list[2].select_one(\"img\")[\"src\"] else \"down\"\n",
    "      \n",
    "      td = [\n",
    "        td_list[0].getText().strip().replace(\".\", \"-\"), \n",
    "        after,\n",
    "        origin, \n",
    "        state, \n",
    "        td_list[1].getText().strip().replace(\",\", \"\"), \n",
    "        td_list[2].getText().strip().replace(\",\", \"\"), \n",
    "        td_list[4].getText().strip().replace(\",\", \"\"),\n",
    "        td_list[5].getText().strip().replace(\",\", \"\"),\n",
    "        td_list[6].getText().strip().replace(\",\", \"\"),\n",
    "        ]\n",
    "      \n",
    "      if state != \"same\":\n",
    "        change_rate = round(int(td[5]) / ( int(td[4]) + (int(td[5]) if state == \"down\" else (-int(td[5])))) * 100, 1)\n",
    "        td.append(change_rate)\n",
    "      else:\n",
    "        td.append(0)\n",
    "      \n",
    "      cur_date = dt.datetime.strptime(td[0], \"%Y-%m-%d\")\n",
    "      start_diff = (cur_date - start).total_seconds()\n",
    "      end_diff= (end - cur_date).total_seconds()\n",
    "      if start_diff < 0 or end_diff <= 0:\n",
    "        continue\n",
    "      \n",
    "      result_list.append(\"('{}', '{}', '{}', '{}', {}, {}, {}, {}, {}, {})\".format(td[0], td[1], td[2], td[3], td[4], td[5], td[6], td[7], td[8], td[9]))\n",
    "  except Exception as ex:\n",
    "    print(\"stock_bs 오류 발생\", td_list[0].getText().strip())\n",
    "    print(ex)\n",
    "  \n",
    "  return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Desc: 100%|███████████████████████████████████| 297/297 [03:17<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = stock_api(\"006280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2957,\n",
       " \"('2011-01-03', 'H 생명', '녹십자', 'up', 140000, 1000, 140500, 138000, 43583, 0.7)\",\n",
       " \"('2022-12-29', 'H 생명', '녹십자', 'down', 129500, 4000, 133500, 128000, 27725, 3.0)\")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list), result_list[0], result_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(stock_녹십자_230420).p\", \"wb\") as f:\n",
    "  pickle.dump(result_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(stock_temp_230414).p\", \"rb\") as f:\n",
    "  result_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pymysql.connect(host='localhost', user='ssafy', password='ssafy', \n",
    "                      db='access_db', charset='utf8mb4', autocommit=True)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO stock(stock_date, stock_name, stock_name_origin, stock_state, stock_rate, stock_change, stock_low, stock_high, stock_volume, stock_change_rate) VALUES \" + \",\".join(result_list)\n",
    "cur.execute(sql)\n",
    "con.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주식 뉴스!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용 주식 머시깽이들\n",
    "  - 전기 : 삼성전자(005930), LG전자(066570)\n",
    "  - 화학 : LG화학(051910), 롯데케미칼(011170)\n",
    "  - 생명 : 셀트리온(068270), 녹십자(006280)\n",
    "  - IT : Naver(035420), SK텔레콤(017670)\n",
    "  - 엔터 : SM엔터테이먼트(041510), JYP엔터테이먼트(035900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### api 함수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예시 : https://search.naver.com/search.naver?where=news&query={키워드}&sm=tab_opt&sort=0&photo=3&field=0&pd=3&ds={YYYY.MM.DD}&de={YYYY.MM.DD}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom{YYYYMMDD}to{YYYYMMDD}&is_sug_officeid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정 : 일별로 최대 5개 추출!\n",
    "def news_api(news_type):\n",
    "  if news_type == \"네이버\":\n",
    "    after = \"G IT\"\n",
    "  elif news_type == \"삼성전자\":\n",
    "    after = \"A 전자\"\n",
    "  elif news_type ==\"LG화학\":\n",
    "    after = \"B 화학\"\n",
    "  elif news_type ==\"셀트리온\":\n",
    "    after = \"C 생명\"\n",
    "  elif news_type ==\"SM엔터\":\n",
    "    after = \"E 엔터테이먼트\"\n",
    "  elif news_type ==\"LG전자\":\n",
    "    after = \"F 전자\"\n",
    "  elif news_type ==\"롯데케미칼\":\n",
    "    after = \"G 화학\"\n",
    "  elif news_type ==\"녹십자\":\n",
    "    after = \"H 생명\"\n",
    "  elif news_type ==\"SK텔레콤\":\n",
    "    after = \"I IT\"\n",
    "  elif news_type ==\"JYP엔터\":\n",
    "    after = \"J 엔터테이먼트\"\n",
    "    \n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\", 'User-Agent': 'Mozilla/5.0'}\n",
    "  \n",
    "  result_list = []\n",
    "  result_list_all = []\n",
    "  # 검색 결과는 최대 4000개 보여주므로 각 년도의 분기별로 기사 추출.\n",
    "  st = dt.datetime.now()\n",
    "  print(\"시작 시간 : {}\".format(st))\n",
    "  keyword = urllib.parse.quote(news_type)\n",
    "  for cur_date in pd.date_range(start=\"1/1/2011\", end=\"12/31/2022\"):\n",
    "    cur = cur_date.strftime(\"%Y.%m.%d\")\n",
    "    \n",
    "    try:\n",
    "      url = \"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=0&photo=3&field=0&pd=3&ds={date1}&de={date1}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom{date2}to{date2}&is_sug_officeid=0\".format(keyword=keyword, date1=cur, date2=cur.replace(\".\", \"\"))\n",
    "      req = Request(url, headers=headers)\n",
    "      with urlopen(req) as response:\n",
    "        if not response is None:\n",
    "          new_result_list, new_result_list_all = news_bs(response, news_type, after)\n",
    "          result_list.extend(new_result_list)\n",
    "          result_list_all.extend(new_result_list_all)\n",
    "\n",
    "    except Exception as ex:\n",
    "      print(\"news_api 오류 발생\")\n",
    "      print(ex)\n",
    "    finally:\n",
    "      if cur.split(\".\")[2] == \"01\":\n",
    "        current = dt.datetime.strptime(cur, \"%Y.%m.%d\")\n",
    "        past_date = current  - dt.timedelta(days=1)\n",
    "        if(past_date.year != 2010):\n",
    "          print(past_date.strftime(\"%Y.%m\"), end=\" \")\n",
    "          if(current.year != past_date.year):\n",
    "            print()\n",
    "      time.sleep(0.3)\n",
    "    \n",
    "  print()  \n",
    "  et = dt.datetime.now()\n",
    "  print(\"종료 시간 : {}\".format(et))\n",
    "  \n",
    "  # 소요 시간(초)\n",
    "  diff = int((et-st).total_seconds())\n",
    "  \n",
    "  # 소요 시간 세부 항목 계산\n",
    "  total_hour = int(diff // 3600)\n",
    "  diff = int(diff % 3600)\n",
    "  total_minute = int(diff // 60)\n",
    "  total_second = int(diff % 60)\n",
    "  print(\"소요 시간 : {}시간 {}분 {}초\".format(total_hour, total_minute, total_second))\n",
    "  \n",
    "  return result_list, result_list_all\n",
    "\n",
    "def news_bs(response, origin, after):\n",
    "  soup = bs(response, \"lxml\")\n",
    "  result = soup.select(\"ul.list_news > li.bx\")  # 기사 타이틀이 들어있는 태그 리스트\n",
    "  \n",
    "  result_list = [] # 결과 저장(기업명 포함 기사만 저장)\n",
    "  result_list_all = [] # 모든 결과 저장\n",
    "  try:\n",
    "    for idx, p in enumerate(result[:5]):\n",
    "      cur_date = p.select(\".info\")[2].get_text().strip()[:-1].replace(\".\", \"-\")  # 날짜\n",
    "      cur_title = p.select_one(\".news_tit\").get_attribute_list(\"title\")[0]  # 타이틀\n",
    "      cur_title = cur_title.replace(\"`\", '\"').replace(\"'\", '\"')\n",
    "      \n",
    "      result = \"('{}', '{}', '{}', '{}')\".format(cur_date, origin, after, cur_title)\n",
    "      if idx < 3 : result_list_all.append(result)\n",
    "      if origin in cur_title: result_list.append(result)\n",
    "  except Exception as ex:\n",
    "    print(\"news_bs 오류 발생\")\n",
    "    print(ex)\n",
    "  \n",
    "  return result_list, result_list_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이전 코드 : 모든 검색 결과에서 기업명이 들어간 타이틀만 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_api(news_type):\n",
    "  if news_type == \"네이버\":\n",
    "    stock = \"G IT\"\n",
    "    \n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\", 'User-Agent': 'Mozilla/5.0'}\n",
    "  \n",
    "  result_list = []\n",
    "  # 검색 결과는 최대 4000개 보여주므로 각 년도의 분기별로 기사 추출.\n",
    "  st = dt.datetime.now()\n",
    "  print(\"시작 시간 : {}\".format(st))\n",
    "  for year in range(2011, 2023):\n",
    "    print(\"{}년도\".format(year), end=\" \")\n",
    "    for month in range(1, 13):\n",
    "      nextDate = (dt.datetime(year, month+1, 1) if month < 12 else dt.datetime(year+1, 1, 1))  - dt.timedelta(days=1)\n",
    "      lastDate = nextDate.strftime(\"%Y.%m.%d\")\n",
    "      dateList = [('%d.%02d.%02d' %(year, month, 1), '%d.%02d.%02d' %(year, month, 15)),\n",
    "                  ('%d.%02d.%02d' %(year, month, 16), lastDate)]\n",
    "      \n",
    "      keyword = urllib.parse.quote(news_type)\n",
    "      \n",
    "      for startDate, endDate in dateList:\n",
    "        HOST = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query={}&sort=2&photo=3&field=0&pd=3&ds={}&de={}&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{}to{},a:all&start=\".format(keyword, startDate, endDate, startDate.replace(\".\", \"\"), endDate.replace(\".\", \"\"))\n",
    "        \n",
    "        try:\n",
    "          page = 1\n",
    "          max_page = 1\n",
    "          while True:\n",
    "            url = HOST + str(page)\n",
    "            req = Request(url, headers=headers)\n",
    "            with urlopen(req) as response:\n",
    "              if not response is None:\n",
    "                new_result_list, is_next = news_bs(response, news_type, stock)\n",
    "                result_list.extend(new_result_list)\n",
    "                \n",
    "                # 다음 페이지가 있다면 계속 탐색\n",
    "                if is_next : \n",
    "                  page = page + 10\n",
    "                else :\n",
    "                  break\n",
    "            time.sleep(0.1)\n",
    "          max_page = max(max_page, page)\n",
    "        except Exception as ex:\n",
    "          print(\"news_api 오류 발생\")\n",
    "          print(ex)\n",
    "      print(\"{}\".format(month), end=\" \")\n",
    "    print(\"완료! : {}, 최대 페이지 : {}\".format(dt.datetime.now(), max_page))\n",
    "  \n",
    "  et = dt.datetime.now()\n",
    "  print(\"종료 시간 : {}\".format(et))\n",
    "  \n",
    "  # 소요 시간(초)\n",
    "  diff = int((et-st).total_seconds())\n",
    "  \n",
    "  # 소요 시간 세부 항목 계산\n",
    "  total_hour = int(diff // 3600)\n",
    "  diff = int(diff % 3600)\n",
    "  total_minute = int(diff // 60)\n",
    "  total_second = int(diff % 60)\n",
    "  print(\"소요 시간 : {}시간 {}분 {}초\".format(total_hour, total_minute, total_second))\n",
    "  \n",
    "  return result_list\n",
    "\n",
    "def news_bs(response, origin, after):\n",
    "  soup = bs(response, \"lxml\")\n",
    "  result = soup.select(\"ul.list_news > li.bx\")  # 기사 타이틀이 들어있는 태그 리스트\n",
    "  btn_next = soup.select_one(\"a.btn_next\")  # 다음 페이지 버튼\n",
    "  \n",
    "  # 다음 페이지가 있는지 검사\n",
    "  is_next = False if btn_next.get_attribute_list(\"href\")[0] is None else True\n",
    "  \n",
    "  result_list = [] # 결과 저장\n",
    "  try:\n",
    "    for p in result:\n",
    "      cur_date = p.select(\".info\")[2].get_text().strip()[:-1].replace(\".\", \"-\")  # 날짜\n",
    "      cur_title = p.select_one(\".news_tit\").get_attribute_list(\"title\")[0]  # 타이틀\n",
    "      cur_title = cur_title.replace(\"`\", '\"').replace(\"'\", '\"')\n",
    "      \n",
    "      if origin not in cur_title:\n",
    "        continue\n",
    "      \n",
    "      result_list.append(\"('{}', '{}', '{}', '{}')\".format(cur_date, origin, after, cur_title))\n",
    "  except Exception as ex:\n",
    "    print(\"stock_bs 오류 발생\")\n",
    "    print(ex)\n",
    "  \n",
    "  return result_list, is_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 2018년도 추출용!\n",
    "def news_api(news_type):\n",
    "  if news_type == \"네이버\":\n",
    "    stock = \"G IT\"\n",
    "    \n",
    "  headers = {\"Content-Type\" : \"application/json\", \"charset\" : \"UTF-8\", \"Accept\":\"*/*\", 'User-Agent': 'Mozilla/5.0'}\n",
    "  \n",
    "  result_list = []\n",
    "  # 검색 결과는 최대 4000개 보여주므로 각 년도의 분기별로 기사 추출.\n",
    "  st = dt.datetime.now()\n",
    "  print(\"시작 시간 : {}\".format(st))\n",
    "  for year in range(2018, 2019):\n",
    "    print(\"{}년도\".format(year), end=\" \")\n",
    "    for month in range(1, 13):\n",
    "      nextDate = (dt.datetime(year, month+1, 1) if month < 12 else dt.datetime(year+1, 1, 1))  - dt.timedelta(days=1)  \n",
    "      lastDate = nextDate.strftime(\"%Y.%m.%d\")\n",
    "      dateList = [('%d.%02d.%02d' %(year, month, 1), '%d.%02d.%02d' %(year, month, 15)),\n",
    "                  ('%d.%02d.%02d' %(year, month, 16), lastDate)]\n",
    "      \n",
    "      keyword = urllib.parse.quote(news_type)\n",
    "      \n",
    "      for startDate, endDate in dateList:\n",
    "        HOST = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query={}&sort=2&photo=3&field=0&pd=3&ds={}&de={}&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{}to{},a:all&start=\".format(keyword, startDate, endDate, startDate.replace(\".\", \"\"), endDate.replace(\".\", \"\"))\n",
    "        \n",
    "        try:\n",
    "          page = 1\n",
    "          max_page = 1\n",
    "          while True:\n",
    "            url = HOST + str(page)\n",
    "            req = Request(url, headers=headers)\n",
    "            with urlopen(req) as response:\n",
    "              if not response is None:\n",
    "                new_result_list, is_next = news_bs(response, news_type, stock)\n",
    "                result_list.extend(new_result_list)\n",
    "                \n",
    "                # 다음 페이지가 있다면 계속 탐색\n",
    "                if is_next : \n",
    "                  page = page + 10\n",
    "                else :\n",
    "                  break\n",
    "            time.sleep(0.1)\n",
    "          max_page = max(max_page, page)\n",
    "        except Exception as ex:\n",
    "          print(\"news_api 오류 발생\")\n",
    "          print(ex)\n",
    "      print(\"{}\".format(month), end=\" \")\n",
    "    print(\"완료! : {}, 최대 페이지 : {}\".format(dt.datetime.now(), max_page))\n",
    "  \n",
    "  et = dt.datetime.now()\n",
    "  print(\"종료 시간 : {}\".format(et))\n",
    "  \n",
    "  # 소요 시간(초)\n",
    "  diff = int((et-st).total_seconds())\n",
    "  \n",
    "  # 소요 시간 세부 항목 계산\n",
    "  total_hour = int(diff // 3600)\n",
    "  diff = int(diff % 3600)\n",
    "  total_minute = int(diff // 60)\n",
    "  total_second = int(diff % 60)\n",
    "  print(\"소요 시간 : {}시간 {}분 {}초\".format(total_hour, total_minute, total_second))\n",
    "  \n",
    "  return result_list\n",
    "\n",
    "def news_bs(response, origin, after):\n",
    "  soup = bs(response, \"lxml\")\n",
    "  result = soup.select(\"ul.list_news > li.bx\")  # 기사 타이틀이 들어있는 태그 리스트\n",
    "  btn_next = soup.select_one(\"a.btn_next\")  # 다음 페이지 버튼\n",
    "  \n",
    "  # 다음 페이지가 있는지 검사\n",
    "  is_next = False if btn_next.get_attribute_list(\"href\")[0] is None else True\n",
    "  \n",
    "  result_list = [] # 결과 저장\n",
    "  try:\n",
    "    for p in result:\n",
    "      cur_date = p.select(\".info\")[2].get_text().strip()[:-1].replace(\".\", \"-\")  # 날짜\n",
    "      cur_title = p.select_one(\".news_tit\").get_attribute_list(\"title\")[0]  # 타이틀\n",
    "      cur_title = cur_title.replace(\"`\", '\"').replace(\"'\", '\"')\n",
    "      \n",
    "      if origin not in cur_title:\n",
    "        continue\n",
    "      \n",
    "      result_list.append(\"('{}', '{}', '{}', '{}')\".format(cur_date, origin, after, cur_title))\n",
    "  except Exception as ex:\n",
    "    print(\"stock_bs 오류 발생\")\n",
    "    print(ex)\n",
    "  \n",
    "  return result_list, is_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 시간 : 2023-04-20 15:29:04.486418\n",
      "2011.01 2011.02 2011.03 2011.04 2011.05 2011.06 2011.07 2011.08 2011.09 2011.10 2011.11 2011.12 \n",
      "2012.01 2012.02 2012.03 2012.04 2012.05 2012.06 2012.07 2012.08 2012.09 2012.10 2012.11 2012.12 \n",
      "2013.01 2013.02 2013.03 2013.04 2013.05 2013.06 2013.07 2013.08 2013.09 2013.10 2013.11 2013.12 \n",
      "2014.01 2014.02 2014.03 2014.04 2014.05 2014.06 2014.07 2014.08 2014.09 2014.10 2014.11 2014.12 \n",
      "2015.01 2015.02 2015.03 2015.04 2015.05 2015.06 2015.07 2015.08 2015.09 2015.10 2015.11 2015.12 \n",
      "2016.01 2016.02 2016.03 2016.04 2016.05 2016.06 2016.07 2016.08 2016.09 2016.10 2016.11 2016.12 \n",
      "2017.01 2017.02 2017.03 2017.04 2017.05 2017.06 2017.07 2017.08 2017.09 2017.10 2017.11 2017.12 \n",
      "2018.01 2018.02 2018.03 2018.04 2018.05 2018.06 2018.07 2018.08 2018.09 2018.10 2018.11 2018.12 \n",
      "2019.01 2019.02 2019.03 2019.04 2019.05 2019.06 2019.07 2019.08 2019.09 2019.10 2019.11 2019.12 \n",
      "2020.01 2020.02 2020.03 2020.04 2020.05 2020.06 2020.07 2020.08 2020.09 2020.10 2020.11 2020.12 \n",
      "2021.01 2021.02 2021.03 2021.04 2021.05 2021.06 2021.07 2021.08 2021.09 2021.10 2021.11 2021.12 \n",
      "2022.01 2022.02 2022.03 2022.04 2022.05 2022.06 2022.07 2022.08 2022.09 2022.10 2022.11 \n",
      "종료 시간 : 2023-04-20 16:15:15.610484\n",
      "소요 시간 : 0시간 46분 11초\n"
     ]
    }
   ],
   "source": [
    "result_list, result_list_all = news_api(\"JYP엔터\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 1364)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list), len(result_list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(news_JYP엔터_230420).p\", \"wb\") as f:\n",
    "  pickle.dump(result_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data(news_naver_230417).p\", \"rb\") as f:\n",
    "  result_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pymysql.connect(host='localhost', user='ssafy', password='ssafy', \n",
    "                      db='access_db', charset='utf8mb4', autocommit=True)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO news_origin(news_date, news_name_origin, news_name, news_content) VALUES \" + \",\".join(result_list)\n",
    "cur.execute(sql)\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
